---------------------Video 2 Lecture----------------------------

Linear Regression

1. SSE = E1^2 + E2^2 +.... En^2
2. SST = summation((y-mean(y))^2)               NOTE: Baseline Model = mean(y)
3. RMSE = sqrt(SSE/n)
4. R^2 = 1- (SSE/SST)
NOTE: Desirable -> R^2 near to 1... Not desirable -> R^2 near to 0
----------------------------------------------------------------

---------------------Video 3 Lecture----------------------------

Multiple Linear Regression

1. yi = B0 + B1x1 + B2x2 + B3x3 +....
2. With more variables, the R^2 increases
3. Should create the perfect fit. Avoid Overfitting: Which even though has high R^2 
   to 1, but has lower predictibility.

----------------------------------------------------------------

---------------------Video 4 Lecture----------------------------

Linear Regression in R

1. Multiple R squared: Increases with increase in independent variables. 
2. Adjusted R squared: Should increase realistically with stronger models. 

----------------------------------------------------------------

---------------------Video 5 Lecture----------------------------

Understanding the Model

1. If coefficient is not significantly different from 0, then should be removed as
   it is not affecting much and will lead to overfitting
2. Std Error gives how much the coefficient is gonna vary from the estimate value
3. T-Value is the estimate/Standard Error: Larger t value gives the importance of 
   the variable in the model
4. Possibility that the coeff is 0. The lesser the number, the lesser the 
   possibility. We want lesser Pr> |t| in our model.
5. However, we can see the stars at the end of the model. This represents the 
   importance of variable.
6. Multicollineararity: Age and France Population are highly correlated.

----------------------------------------------------------------

---------------------Video 6 Lecture----------------------------

Correlation and Multicollinearity

1. Relationship btw the variables: lies between -1 and 1. -1: perfect negative
   linear relationship, 1: Perfect positive lr, 0: No lr
2. Note the correlation formula
3. |cor|> 0.7 is concerning and should be considered.

----------------------------------------------------------------

---------------------Video 7 Lecture----------------------------

Making Predictions

1. Training data and Test data
2. Good Model: Model R^2 and Test R^2 both are high and closer to 1.
3. Test R^2 can be negative as it can perform worse than the baseline model while 
   testing.

----------------------------------------------------------------

