parole = read.csv('parole.csv')
str(parole)
table(parole$violator)
parole$state = as.factor(parole$state)
parole$crime = as.factor(parole$crime)
summary(parole$state) 
summary(parole$crime)
set.seed(144)
library(caTools)
split = sample.split(parole$violator, SplitRatio = 0.7)
train = subset(parole, split == TRUE)
test = subset(parole, split == FALSE)
model = glm(violator~.,data='train',family='binomial')
model = glm(violator~.,data=train,family=binomial)
summary(model)
#From the logistic regression equation, we have log(odds) = -4.2411574 + 0.3869904*male + 0.8867192*race - 0.0001756*age + 0.4433007*state2 + 0.8349797*state3 - 3.3967878*state4 - 0.1238867*time.served + 0.0802954*max.sentence + 1.6119919*multiple.offenses + 0.6837143*crime2 - 0.2781054*crime3 - 0.0117627*crime4. This parolee has male=1, race=1, age=50, state2=0, state3=0, state4=0, time.served=3, max.sentence=12, multiple.offenses=0, crime2=1, crime3=0, crime4=0. We conclude that log(odds) = -1.700629.
#Therefore, the odds ratio is exp(-1.700629) = 0.183, and the predicted probability of violation is 1/(1+exp(1.700629)) = 0.154.
predictions = predict(model, newdata=test, type="response")
summary(predictions)
table(test$violator, predictions>=0.5)
(167+12)/(167+12+11+12)
167/(167+12)
11/23
12/23
# What is the accuracy of a simple model that predicts that every parolee is a non-violator?
(167+12)/nrow(test)
library(ROCR)
pred = prediction(predictions, test$violator)
as.numeric(performance(pred, "auc")@y.values)
q()
q()
